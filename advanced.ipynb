{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Model Merging Function\n",
    "\n",
    "To fully leverage the capabilities of this library, it's important to understand some of its inner workings. The library is designed to be easily extendable, making it simple to customize and build upon. To facilitate this, the library provides two key Python function decorators:\n",
    "\n",
    "## `@model_merge` Decorator\n",
    "\n",
    "The `@model_merge` decorator is designed to wrap around your outer merging function, taking care of complex operations such as model loading, casting to and from `StateDict`, and managing skipped layers. When you apply this decorator to a function, it allows the function to accept a list of either `torch.nn.Module` objects or Hugging Face pipelines as input, and it will output a similarly structured object.\n",
    "\n",
    "However, the core merging logic that you need to implement is much simpler. Your function only needs to accept a list of `StateDict` objects (which represent the state of each model) and return a `StateDict` for the merged model. The `@model_merge` decorator handles all the other complexities for you!\n",
    "\n",
    "\n",
    "```python\n",
    "@model_merge\n",
    "def my_merge_function(models: List[StateDict], **kw) -> StateDict:\n",
    "    # Your merging logic here\n",
    "    return merged_state_dict\n",
    "\n",
    "my_merge_function(list_of_models)\n",
    "```\n",
    "\n",
    "## `@dict_map` Decorator\n",
    "\n",
    "The `@dict_map` decorator is intended to wrap the inner function that performs the actual layer-wise merging of the models.\n",
    "\n",
    "This decorator enables you to write a function that operates on individual layers (i.e., `torch.Tensor` objects) and then applies this function across all the layers in the model. The function you write should take as input a `List[torch.Tensor]`—each tensor representing the parameters for a specific layer across different models—and return a single tensor representing the merged layer.\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "```python\n",
    "@dict_map()\n",
    "def merge_layers(models: List[Tensor], **kw) -> torch.Tensor:\n",
    "    # Your layer-wise merging logic here\n",
    "    return merged_layer\n",
    "```\n",
    "\n",
    "By using these decorators, you can focus on the core logic of merging models and layers without worrying about the underlying complexities of model management. This makes your code more modular, readable, and maintainable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median Merger\n",
    "Imagine you hypothesize that taking the median value of the weights from several models might improve their overall performance compared to the original models. How would you go about implementing this idea?\n",
    "\n",
    "### Step 1: Implementing the Layer-Wise Median Merger\n",
    "\n",
    "The first step is to create a function that performs the merging operation on a layer-by-layer basis. This function will be wrapped with the `@dict_map` decorator to apply your merging logic across all layers of the model.\n",
    "\n",
    "In this example, the merging strategy involves stacking the weights from each model and then taking the median across this stacked dimension. This approach ensures that the resulting weights are representative of the central tendency across all models.\n",
    "\n",
    "Here’s how you can implement this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from transformers import pipeline\n",
    "from typing import List\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "from mergecraft import layer_merge, StateDict, dict_map, model_merge\n",
    "\n",
    "@dict_map\n",
    "def median_layer_merging(models: List[Tensor], **kw) -> Tensor:\n",
    "    return torch.median(torch.stack(models), dim=0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Applying the Median Merger to the Entire Model\n",
    "\n",
    "Once the layer-wise merging function is defined, you can use it within a model-merging function. This function will be decorated with `@model_merge` to handle the higher-level tasks, like converting models to `StateDict` and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model_merge\n",
    "def median(models: List[StateDict], **kw) -> StateDict:\n",
    "    return median_layer_merging(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How It Works:\n",
    "\n",
    "1. **Layer-wise Median Calculation**: The `median_merge_layers` function stacks the corresponding layers from each model and computes the median value across them.\n",
    "2. **Model-wide Application**: The `@dict_map` decorator applies this median calculation across all layers in the model, while `@model_merge` manages the conversion and overall structure.\n",
    "\n",
    "This process allows you to easily merge multiple models using the median of their weights, potentially improving performance by leveraging the central tendencies of the models' parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Merged Model\n",
    "\n",
    "To assess the effectiveness of our novel merging approach, we can apply it to a real-world scenario. For this example, we'll use the BERT model and the RTE (Recognizing Textual Entailment) task from the GLUE benchmark.\n",
    "\n",
    "\n",
    "First, we'll load a set of pre-trained BERT models that have been fine-tuned on the RTE task. These models will be used as input for our median merging function.\n",
    "\n",
    "Next, we will apply our median merging function to these models. The process involves merging the models' weights using the median strategy, as previously defined, and then evaluating the merged model's performance on the text classification task.\n",
    "\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "- **Model Selection**: The list of models includes various versions of the BERT model, each fine-tuned on the RTE task. This diversity can help ensure that the median merger captures a well-rounded set of weights.\n",
    "\n",
    "- **Task Specification**: The `task='text-classification'` parameter tells the library that we're working with a classification task, which is essential for correctly loading the models from huuggingface.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9min 37s\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = ['textattack/bert-base-uncased-RTE', 'yoshitomo-matsubara/bert-base-uncased-rte', 'Ruizhou/bert-base-uncased-finetuned-rte', 'howey/bert-base-uncased-rte', 'anirudh21/bert-base-uncased-finetuned-rte']\n",
    "\n",
    "merged_model = median(models, task='text-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.592057761732852}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mergecraft import evaluate_glue_pipeline\n",
    "evaluate_glue_pipeline(merged_model, 'rte')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping Up\n",
    "\n",
    "Congratulations! You've just implemented, run, and evaluated a completely novel model merging approach. While the process was successful, the results didn't quite meet our expectations—our merged model achieved an accuracy of 0.59, which is lower than the baseline models, whose accuracies range between 0.66 and 0.72.\n",
    "\n",
    "### Reflections on the Results\n",
    "\n",
    "Although this method wasn't as effective as we initially hoped and proved to be quite time-consuming, this is all part of the experimentation process. Every attempt, successful or not, brings valuable insights. By understanding what doesn't work, we're one step closer to discovering what does.\n",
    "\n",
    "### Looking Forward\n",
    "\n",
    "Don't be discouraged by these results! The beauty of this framework is its flexibility—you can easily tweak, modify, and re-run your merging strategies as often as needed. With each iteration, you're refining your approach and inching closer to a more effective solution.\n",
    "\n",
    "Remember, innovation often comes from persistence. So keep experimenting, iterating, and learning until you develop a merging method that not only works but excels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplified Merging with `@layer_merge`\n",
    "\n",
    "If you look closely at the `median()` function, you'll notice that it's mainly passing parameters down the chain without doing much on its own. This is typical for simple merging methods like the ones we've explored. \n",
    "\n",
    "To further simplify the construction of merging methods, the `mergecraft` library provides a `@layer_merge` decorator. This decorator combines the functionalities of `@dict_map` and `@model_merge` into one, making the process more straightforward. Here’s how it works:\n",
    "\n",
    "```python\n",
    "def layer_merge(func) -> Callable:\n",
    "    func = dict_map(func)\n",
    "    func = model_merge(func)\n",
    "    return func\n",
    "```\n",
    "\n",
    "With `@layer_merge`, you can simplify the median merger even further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@layer_merge\n",
    "def median(models: List[Tensor], **kw) -> Tensor:\n",
    "    return torch.median(torch.stack(models), dim=0).values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
